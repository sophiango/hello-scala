# ğŸš€ Data Engineering & Analysis Practice with Apache Spark

Welcome to my **personal learning playground** for exploring **Data Engineering and Analytics** using:

- âš¡ **Apache Spark (Scala & SQL)**
- ğŸ—‚ï¸ **Big Data concepts (ETL, Parquet, DAGs, window functions, etc.)**
- ğŸ“Š **Data analysis techniques** for building pipelines and insights

This repo is **not a polished project**, but rather a **hands-on lab** where I practice new concepts daily, experiment with Spark APIs, and document my learning journey.

---

## ğŸ“– Goals of This Repo
âœ”ï¸ Learn Spark internals (DAGs, lazy evaluation, transformations vs actions)  
âœ”ï¸ Practice **DataFrame API** and **Spark SQL** side by side  
âœ”ï¸ Work with real-world datasets (CSV, Parquet, JSON)  
âœ”ï¸ Explore **data engineering workflows**: ingestion â†’ cleaning â†’ transformation â†’ analysis  
âœ”ï¸ Build intuition for performance (caching, partitioning, cluster execution)  
âœ”ï¸ Strengthen **Scala coding** skills while practicing **SQL queries**

---

## ğŸ› ï¸ Tech Stack

- **Apache Spark** (local mode for now)
- **Scala** (via sbt build tool)
- **Spark SQL** for relational-style analysis
- **Parquet & CSV** for dataset storage formats
- (Later) ğŸ’¡ Potential to add: Airflow, dbt, Delta Lake

---

## ğŸƒ Running the Code
1. Clone the repo
```declarative
git clone git@github.com:sophiango/hello-scala.git
cd hello-scala
```
2. Run with sbt
```declarative
sbt run
```
---

## ğŸŒŸ Learning Journey
Iâ€™m using this repo as a daily practice log for:

- Day 1 â†’ Spark setup, RDDs vs DataFrames, first DAGs 
- Day 2 â†’ Filtering nulls, aggregations, Parquet intro 
- Day 3 â†’ Window functions, ranking, explode() for genres
- (More coming soon...)

--- 

## ğŸ“Œ Notes
This is a work-in-progress repo âœ¨ built for learning and experimentation.
Itâ€™s not production-ready but instead a showcase of my hands-on growth in data engineering and analytics.